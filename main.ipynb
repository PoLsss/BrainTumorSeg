{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Connect to drive and import some library"],"metadata":{"id":"TgjBwq_nJJUr"}},{"cell_type":"code","source":["!pip install SimpleITK\n","!pip install monai"],"metadata":{"id":"K6XUWec83bhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2i3pf5QbDgKC","executionInfo":{"status":"ok","timestamp":1715500397244,"user_tz":-420,"elapsed":18839,"user":{"displayName":"Quá Nguyễn","userId":"14480045489611476895"}},"outputId":"bfcafac7-0e3b-436a-e029-96c6ad0d9613"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Code_BrainTumorSeg_Conf/')"],"metadata":{"id":"u1nAdWyHdavr","executionInfo":{"status":"ok","timestamp":1715500399663,"user_tz":-420,"elapsed":339,"user":{"displayName":"Quá Nguyễn","userId":"14480045489611476895"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import SimpleITK as sitk\n","import numpy as np\n","import torch\n","from sklearn.model_selection import KFold\n","from torch.utils.data.dataset import Dataset\n","import argparse\n","import os\n","import random\n","import pathlib\n","import time\n","from datetime import datetime\n","import torch.backends.cudnn as cudnn\n","import torch.nn.parallel\n","import torch.optim\n","import torch.utils.data\n","import yaml\n","from torch.autograd import Variable\n","from monai.data import decollate_batch\n","from monai.losses import DiceLoss\n","from torch.utils.tensorboard import SummaryWriter\n","import matplotlib.pyplot as plt\n","\n","from brats_ import *\n","from metrics import *\n","from preprocessing import *\n","from logfile import LOGGER\n","from train_val_epoch import *\n"],"metadata":{"id":"2gk3_zCm3BJy","executionInfo":{"status":"ok","timestamp":1715500421221,"user_tz":-420,"elapsed":19996,"user":{"displayName":"Quá Nguyễn","userId":"14480045489611476895"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["BRATS_TRAIN_FOLDERS = f\"/path/to/yourdata\"\n","\n","def get_brats_folder(on=\"train\"):\n","    if on == \"train\":\n","        return BRATS_TRAIN_FOLDERS"],"metadata":{"collapsed":true,"id":"3sUKRB_03HhL","executionInfo":{"status":"ok","timestamp":1715500425074,"user_tz":-420,"elapsed":334,"user":{"displayName":"Quá Nguyễn","userId":"14480045489611476895"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Load data"],"metadata":{"id":"ixWstBZ94Qkd"}},{"cell_type":"code","source":["def get_datasets(seed, on=\"train\", fold_number=0, normalisation=\"zscore\"):\n","    base_folder = pathlib.Path(get_brats_folder(on)).resolve()\n","    assert base_folder.exists()\n","    patients_dir = sorted([x for x in base_folder.iterdir() if x.is_dir()])\n","\n","    patients_dir = [x for x in patients_dir]\n","\n","    kfold = KFold(5, shuffle=True, random_state=seed)\n","    print(kfold)\n","    splits = list(kfold.split(patients_dir))\n","    print(splits)\n","    print('________________',splits[fold_number])\n","    train_idx, test_idx = splits[fold_number]\n","\n","#     train_idx = train_idx[: 10]\n","#     test_idx = test_idx[:5]\n","\n","    train = [patients_dir[i] for i in train_idx]\n","    test = [patients_dir[i] for i in test_idx]\n","\n","    train_dataset = Brats(train, training=True, normalisation=normalisation)\n","    test_dataset = Brats(test, training=False, benchmarking=True, normalisation=normalisation)\n","\n","    return train_dataset, test_dataset\n","\n","full_train_dataset, val_dataset = get_datasets(123, fold_number=2)\n","print(len(full_train_dataset), len(val_dataset))"],"metadata":{"id":"MKfd6RUG4XfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Split train and val set\n","train_loader = torch.utils.data.DataLoader(full_train_dataset, batch_size=1, shuffle=True,\n","                                           num_workers=1, pin_memory=True, drop_last=True)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False,\n","                                         pin_memory=True, num_workers=1)\n","\n","print(\"Train dataset number of batch:\", len(train_loader))\n","print(\"Val dataset number of batch:\", len(val_loader))"],"metadata":{"id":"whG1MRlZ4ivF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Show shape of data\n","for batch in train_loader:\n","    # Assuming your input data is a 4D tensor (batch_size, channels, height, width)\n","    data_shape = batch['image'].shape\n","    label_shape = batch['label'].shape\n","    print(\"Data shape in the first batch:\", data_shape)\n","    print(\"Label shape in the first batch:\", label_shape)\n","    break  # Print only the first batch"],"metadata":{"id":"kVHMr61y4sDz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualize some data"],"metadata":{"id":"0PwxKB6P7YNj"}},{"cell_type":"code","source":["# Define a custom colormap with different colors for each label\n","label_colors = ['red','yellow', 'green']\n","\n","# RGB values for the colors\n","color_values = {'red': (255, 0, 0, 255),  'yellow': (255, 255, 0, 255),'green': (0, 255, 0, 255)}\n","\n","background_color = (0, 0, 0, 255)\n","# Assuming you already have the 'train_loader' correctly set up\n","i=0\n","# Get a single batch from the DataLoader\n","for batch in train_loader:\n","    # Assuming batch_size=1, so we only take the first sample\n","    image_sample = batch['image']\n","    label_sample = batch['label']\n","\n","    # Convert tensors to numpy arrays\n","    image_sample_np = image_sample.numpy()\n","    label_sample_np = label_sample.numpy()\n","\n","    # Select the central slice along the z-axis (depth) for visualization\n","    z_slice =  image_sample_np.shape[2] // 2 +2 # between\n","\n","    # Plot each channel of the image sample\n","    num_channels = image_sample_np.shape[1]\n","    fig, axes = plt.subplots(1, num_channels, figsize=(15, 5))\n","\n","    for channel in range(num_channels):\n","        axes[channel].imshow(image_sample_np[0, channel, z_slice], cmap='gray')\n","        axes[channel].set_title(f\"Image Channel {channel + 1}\")\n","\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Plot each channel of the label sample (assuming 3 channels for one-hot encoded segmentation)\n","    num_channels_labels = label_sample_np.shape[1]\n","    fig, axes = plt.subplots(1, num_channels_labels, figsize=(15, 5))\n","\n","    for channel in range(num_channels_labels):\n","        axes[channel].imshow(label_sample_np[0, channel, z_slice], cmap='gray')\n","        axes[channel].set_title(f\"Label Channel {channel + 1}\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","    image_sample_np = np.full((label_sample_np.shape[3], label_sample_np.shape[4], 4), background_color, dtype=np.uint8)\n","    # Combine the label channels with different colors\n","    num_channels_labels = label_sample_np.shape[1]\n","    for channel in range(num_channels_labels-1, -1, -1):\n","        label_channel = label_sample_np[0, channel, z_slice]\n","\n","        # Overlay the label with a unique color\n","        label_color = label_colors[channel % len(label_colors)]\n","        color_value = color_values[label_color]\n","\n","        # Create a mask for the current label channel\n","        label_mask = label_channel > 0\n","\n","        # Apply the color with alpha channel to the corresponding pixels in the composite label\n","        image_sample_np[label_mask] = color_value\n","\n","    # Plot the composite label image\n","    plt.figure(figsize=(10, 5))\n","    plt.imshow(image_sample_np)\n","    plt.title(\"Composite Label\")\n","    plt.show()\n","\n","    i+=1\n","    if i == 1:\n","        break"],"metadata":{"id":"Jpy_z-IU7NYc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model"],"metadata":{"id":"lTGRgW-a8JmW"}},{"cell_type":"code","source":["from models1.unet3d import UNet3d\n","from models1.unet3d_cot import UNet3d_cot\n","from models1.unet3d_da import UNet3d_da\n","from models1.unet3d_da_cot import UNet3d_da_cot\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","## Change model here\n","model = UNet3d_da_cot(in_channels=4, n_classes=3, n_channels=16).to(device)\n","print('Number of network parameters:', sum(param.numel() for param in model.parameters()))"],"metadata":{"id":"wd1fVbspeqvB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Function to train"],"metadata":{"id":"N_nPp-GB8jQV"}},{"cell_type":"code","source":["\n","def trainer(model, train_loader, val_loader, optimizer, loss_func, acc_func, criterian_val, metric, scheduler, batch_size, max_epochs, start_epoch=1):\n","    val_acc_max, best_epoch = 0.0, 0\n","    total_time = time.time()\n","    dices_tc , dices_wt, dices_et, dices_avg, loss_epochs, trains_epoch = [],[], [],[],[],[]\n","\n","    for epoch in range(start_epoch, max_epochs+1):\n","        LOGGER.info(f\"\\n{'=' * 30}Training epoch {epoch}{'=' * 30}\")\n","        epoch_time = time.time()\n","\n","        train_loss = train_epoch(\n","            model,\n","            train_loader,\n","            optimizer,\n","            epoch,\n","            loss_func,\n","            batch_size,\n","            max_epochs,\n","        )\n","        LOGGER.info(f\"Final training epochs: {epoch}/{max_epochs} ---[loss: {train_loss:.4f}] ---[time {time.time() - epoch_time:.2f}s]\")\n","\n","        if scheduler is not None:\n","                scheduler.step()\n","\n","        if (epoch) % val_every == 0 or epoch == max_epochs or epoch == 1:\n","            loss_epochs.append(train_loss)\n","            trains_epoch.append(int(epoch))\n","            epoch_time = time.time()\n","            LOGGER.info(f\"\\t{'*' * 20}Epoch {epoch} Validation{'*' * 20}\")\n","            val_acc = val_epoch(model,\n","                                val_loader,\n","                                epoch=epoch,\n","                                acc_func=acc_func,\n","                                criterian_val = criterian_val,\n","                                metric = metric,\n","                                max_epochs = max_epochs,\n","                                )\n","            dice_et, dice_tc, dice_wt = val_acc[0], val_acc[1], val_acc[2]\n","            val_avg_acc = np.mean(val_acc)\n","            LOGGER.info(f\"\\t{'*' * 20}Epoch Summary{'*' * 20}\")\n","            LOGGER.info(f\"Final validation stats {epoch}/{max_epochs}, dice_et: {dice_et:.6f}, dice_tc: {dice_tc:.6f}, dice_wt: {dice_wt:.6f} , Dice_Avg: {val_avg_acc:.6f} , time {time.time() - epoch_time:.2f}s\")\n","\n","\n","            dices_tc.append(dice_tc)\n","            dices_wt.append(dice_wt)\n","            dices_et.append(dice_et)\n","            dices_avg.append(val_avg_acc)\n","\n","            if val_avg_acc > val_acc_max:\n","                print(\"New best ({:.6f} --> {:.6f}). At epoch {}\".format(val_acc_max, val_avg_acc, epoch))\n","                LOGGER.info(f\"New best ({val_acc_max:.6f} --> {val_avg_acc:.6f}). At epoch {epoch}. Time consuming: {time.time()-total_time:.2f}\")\n","                val_acc_max = val_avg_acc\n","                best_epoch = epoch\n","                torch.save(\n","                    model.state_dict(),\n","                    os.path.join(\"best_metric_model.pth\") ## Change this path to your output model dir,\n","                )\n","            torch.cuda.empty_cache()\n","\n","    LOGGER.info(f\"Training Finished !, Best Accuracy: {val_acc_max:.6f} --At epoch: {best_epoch} --Total_time: {time.time()-total_time:.2f}\")\n","    return (val_acc_max, dices_tc, dices_wt, dices_et, dices_avg, loss_epochs, trains_epoch)"],"metadata":{"id":"V2dMQ3jk8qi-","executionInfo":{"status":"ok","timestamp":1715489280922,"user_tz":-420,"elapsed":521,"user":{"displayName":"Quá Nguyễn","userId":"14480045489611476895"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["start_epoch = 1\n","max_epochs = 100  ## Change number epochs here\n","batch_size = 1\n","val_every = 1\n","\n","criterion = EDiceLoss().to(device)\n","criterian_val = EDiceLoss_Val().to(device)\n","metric = criterian_val.metric\n","###\n","loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\n","\n","\n","dice_acc = DiceMetric(include_background=True, reduction='mean_batch', get_not_nans=True)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n","\n","LOGGER.info(\"[TRAINER] Start TRAIN process...\")\n","\n","(val_acc_max,dices_tc,dices_wt,dices_et,\n","    dices_avg,loss_epochs, trains_epoch,\n",") = trainer(\n","    model = model,\n","    train_loader = train_loader,\n","    val_loader = val_loader,\n","    optimizer = optimizer,\n","    loss_func = criterion,\n","    acc_func = dice_acc,\n","    criterian_val = criterian_val,\n","    metric = metric,\n","    scheduler = scheduler,\n","    batch_size = batch_size,\n","    max_epochs = max_epochs,\n","    start_epoch = start_epoch\n","    )"],"metadata":{"id":"XiOPEwlv8ueq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualize results"],"metadata":{"id":"dVjRaTqiESEp"}},{"cell_type":"code","source":["from visualize_image_results import visualize_results\n","## change this file to your model\n","model_file_out = \"/path/to/yourmodel\"\n","munber_images = 1\n","visualize_results(model, val_loader, model_file_out, munber_images, device)"],"metadata":{"id":"DbONbj2pvRmD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### HD95"],"metadata":{"id":"8jy4eedRFHPf"}},{"cell_type":"code","source":["!pip install medpy"],"metadata":{"id":"1i0VTv9QFUoF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from hd95_metrics import *\n","calc_hd95(model, val_loader, device, model_file_out, max_epochs)"],"metadata":{"id":"jl1n_4fK3eb1"},"execution_count":null,"outputs":[]}]}
